{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2baf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae784e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter here path to project directory\n",
    "infolder = \"/home/mark/final_test_astral/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project directory if it is not exist\n",
    "if not os.path.isdir(infolder):\n",
    "    os.makedirs(infolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15046a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the project directory\n",
    "%cd $infolder\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0703f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download raw files from ProteomeXchange\n",
    "\n",
    "!wget -b ftp://ftp.pride.ebi.ac.uk/pride/data/archive/2024/02/PXD046417/*.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16850981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next step, you should install ThermoRawFileParser (https://github.com/compomics/ThermoRawFileParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ThermoRawFileParser for all raw files with an option to extract only MS1 spectra\n",
    "\n",
    "for fn in os.listdir(infolder):\n",
    "    if fn.endswith('.raw'):\n",
    "        infile1 = os.path.join(infolder, fn)\n",
    "        !ThermoRawFileParser -i $infile1 -L 1 -o $infolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be639e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional)\n",
    "# Remove all raw files which were already converted\n",
    "\n",
    "# for fn in os.listdir(infolder):\n",
    "#     if fn.endswith('.mzML'):\n",
    "#         mzmlfile = os.path.join(infolder, fn)\n",
    "#         rawname = mzmlfile.replace('.mzML', '.raw')\n",
    "#         if os.path.getsize(mzmlfile) > 78502:\n",
    "#             if os.path.exists(rawname):\n",
    "#                 os.remove(rawname)\n",
    "#         else:\n",
    "#             print('small size', mzmlfile, os.path.getsize(mzmlfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a325a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next step, you should install biosaur2 (https://github.com/markmipt/biosaur2)\n",
    "!pip install biosaur2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb51517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run biosaur2 for all mzML files to extract peptide isotope clusters.\n",
    "\n",
    "for fn in os.listdir(infolder):\n",
    "    if fn.endswith('.mzML'):\n",
    "        mzmlname = os.path.join(infolder, fn)\n",
    "        # These are the options for 180 min DDA data\n",
    "        if 'QE5_nLC11' in fn:\n",
    "            !biosaur2 $mzmlname -minlh 5\n",
    "        # These are the options for all Astral data\n",
    "        else:\n",
    "            !biosaur2 $mzmlname -minlh 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baab33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional)\n",
    "# Remove all mzML files which were already converted\n",
    "\n",
    "# for fn in os.listdir(infolder):\n",
    "#     if fn.endswith('.features.tsv'):\n",
    "#         ftrfile = os.path.join(infolder, fn)\n",
    "#         mzmlfile = ftrfile.replace('.features.tsv', '.mzML')\n",
    "#         if os.path.getsize(ftrfile) > 1000:\n",
    "#             if os.path.exists(mzmlfile):\n",
    "#                 os.remove(mzmlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next step, you should install ms1searchpy (https://github.com/markmipt/ms1searchpy)\n",
    "!pip install ms1searchpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next step, you should install DeepLC (https://github.com/compomics/DeepLC)\n",
    "# The recommended version is the clone available at https://github.com/markmipt/DeepLC\n",
    "# The latest official DeepLC versions should work too, but ms1searchpy processing time will be much longer\n",
    "!pip install https://github.com/markmipt/DeepLC/archive/refs/heads/alternative_best_model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e66a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next step, you should put protein fasta database into working directory\n",
    "# The database is placed along this notebook on the github (sprot_human_shuffled.fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75de0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ms1searchpy for all *features.tsv files generated by biosaur2\n",
    "\n",
    "infasta = os.path.join(infolder, 'sprot_human_shuffled.fasta')\n",
    "for fn in os.listdir(infolder):\n",
    "    if fn.endswith('.features.tsv'):\n",
    "        ftrfile = os.path.join(infolder, fn)\n",
    "        protfile = ftrfile.replace('.features.tsv', '.features_proteins.tsv')\n",
    "        if not os.path.exists(protfile):\n",
    "            !ms1searchpy $ftrfile -d $infasta -sc 1 -i 2 -nproc 8 -mc 0 -cmin 1 -ptol 8 -fdr 5 -ts 2 -ml 1 -deeplc 1 -lmin 7 -mcalib 0 -deeplc_library /tmp/deeplc345.lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next step, you should put sample list for MSA and Controls samples into working directory\n",
    "# The sample list is placed along this notebook on the github (Astral_Sample.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0122560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with keys = filename and values = GroupName (MSA or Control)\n",
    "\n",
    "df1 = pd.read_table(os.path.join(infolder, 'Astral_Sample.tsv'))\n",
    "df1['comment[data file]'] = df1['comment[data file]'].str.strip()\n",
    "f_to_cond_map = df1.set_index('comment[data file]')['characteristics[phenotype]'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary which contains list of files used in DirectMS1Quant analysis for 4 runs:\n",
    "# 7min: all 3 technical replicates for 200 SPD data\n",
    "# 7min1r: single techical replicate per sample for 200 SPD data\n",
    "# 28min: 40 SPD data\n",
    "\n",
    "file_dict = dict()\n",
    "\n",
    "file_dict['7min'] = {\n",
    "    'CTRL': [],\n",
    "    'MSA': [],\n",
    "}\n",
    "\n",
    "file_dict['7min1r'] = {\n",
    "    'CTRL': [],\n",
    "    'MSA': [],\n",
    "}\n",
    "\n",
    "file_dict['28min'] = {\n",
    "    'CTRL': [],\n",
    "    'MSA': [],\n",
    "}\n",
    "\n",
    "file_dict['180min'] = {\n",
    "    'CTRL': [],\n",
    "    'MSA': [],\n",
    "}\n",
    "\n",
    "\n",
    "for z in os.listdir(infolder):\n",
    "    if z.endswith('_proteins_full.tsv'):\n",
    "        \n",
    "        if 'NOR_QC' not in z:\n",
    "\n",
    "            zname = z.split('.features')[0]\n",
    "\n",
    "            if '_250ng_01' in z:\n",
    "                \n",
    "                if '2023115_Astral03_Evo5_UHG_SA_DIA_MSA_RR-135_250ng_01' not in z:\n",
    "                \n",
    "                    file_dict['28min'][f_to_cond_map[zname.replace('_250ng_01', '')]].append(os.path.join(infolder, z))\n",
    "            elif 'QE5_nLC11' in z:\n",
    "                sgroup = 'MSA' if 'SA_MSA' in z else 'CTRL'\n",
    "                file_dict['180min'][sgroup].append(os.path.join(infolder, z))\n",
    "            else:\n",
    "\n",
    "                file_dict['7min'][f_to_cond_map[zname]].append(os.path.join(infolder, z))\n",
    "                if 'RR_1_4th' in zname:\n",
    "                    file_dict['7min1r'][f_to_cond_map[zname]].append(os.path.join(infolder, z))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DirectMS1Quant for single techical replicate per sample for 200 SPD data\n",
    "\n",
    "S_first_list = ' '.join(file_dict['7min1r']['CTRL'])\n",
    "S_second_list = ' '.join(file_dict['7min1r']['MSA'])\n",
    "\n",
    "out_name = os.path.join(infolder, 'directms1quant_out_7min1r')\n",
    "!directms1quant\\\n",
    "-S1 $S_first_list\\\n",
    "-S2 $S_second_list -out $out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff291ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DirectMS1Quant for all 3 technical replicates for 200 SPD data\n",
    "\n",
    "S_first_list = ' '.join(file_dict['7min']['CTRL'])\n",
    "S_second_list = ' '.join(file_dict['7min']['MSA'])\n",
    "\n",
    "out_name = os.path.join(infolder, 'directms1quant_out_7min')\n",
    "!directms1quant\\\n",
    "-S1 $S_first_list\\\n",
    "-S2 $S_second_list -out $out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ea7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DirectMS1Quant for 40 SPD data\n",
    "\n",
    "S_first_list = ' '.join(file_dict['28min']['CTRL'])\n",
    "S_second_list = ' '.join(file_dict['28min']['MSA'])\n",
    "\n",
    "out_name = os.path.join(infolder, 'directms1quant_out_28min')\n",
    "!directms1quant\\\n",
    "-S1 $S_first_list\\\n",
    "-S2 $S_second_list -out $out_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
